## My Fair Data: How the Government Can Limit Bias in Artificial Intelligence 
https://www.theatlantic.com/sponsored/booz-allen-hamilton-2018/how-government-can-limit-bias-in-ai/1972/
## Article Summary
This article discusses the presence of significant bias in data, and how this often unchecked ‘out of sight, out of mind’ approach can have serious ethical implications when scaled up with Artificial Intelligence. It talks about how bias in AI can take the form of dataset bias, association bias, interaction bias, automation bias and confirmation bias, and this bias can be the result of mistakes in oversight. Then, this flawed data is used to make assumptions and calculations that do not reflect objectivity. This can be scaled up easily with larger sets of data and discriminate against groups on a large scale. The article also prescribes what the author thinks the government's role should be in safe and responsible AI implementation. This includes establishing standards and guidance to navigate risks around safety, privacy ethics and control. It then suggests that governments should devote public resources to the creation and curation of accurate and bias-free datasets and coordinate with both the public and private sectors.
## Why it spoke to me
I chose to read and respond to this particular article because, through my academic experiences in the digital humanities department, I have developed an awareness of and interest in dataset bias and its implications. As a scholar and citizen, I want to be sure that any time I encounter or directly work with data, that I do not take it at face value. This article and others like it remind me of my personal duty to seek comprehensive, representative, unbiased data. I want to make a positive contribution to society – to help people. But if I want to help solve some of the most pressing issues, it has to start with the basic operationalization of the data itself.
